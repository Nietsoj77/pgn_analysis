{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating playing strength in chess\n",
    "This analysis aims to produce a model that is capable of predicting a player's strength in terms of rating, based on the information from a game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "The data for this project is from a collection of games played on one of the largest chess sites lichess.org.<br><br>\n",
    "\n",
    "The dataset consists of games from a large online tournament, the yearly classical arena (Y4t9Lk9R), which has about 16,000 games. The data can be downloaded via the following link.\n",
    "> https://lichess.org/api/tournament/Y4t9Lk9R/games?evals=true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions about playing strength\n",
    "A frequently used statistic for estimating playing strength is average centipawn loss (aCPL). This will be one of the main variables that we will compare to the players' actual ratings. In addition, the following variables are thought to be of relevance for this analysis:\n",
    "- Rating difference between players\n",
    "- Number of moves played\n",
    "- Number of blunders (big mistakes)\n",
    "- Blunder rate (number of blunders / number of moves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arena_pgn=\"lichess_tournament_2020.05.15_Y4t9Lk9R_yearly-classical.pgn\"\n",
    "\n",
    "# These are the tags we want to extract from the pgn and use as columns in the dataframe\n",
    "# For the tournament data, the timecontrol is not interesting, as all games are played with the same time control\n",
    "# but for general purposes, the tag may be relevant.\n",
    "cols=[\"WhiteElo\",\"BlackElo\",\"TimeControl\",\"ECO\",\"Moves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function separates tags/moves into pairs of keys and values\n",
    "# The function has been tested and validated\n",
    "\n",
    "def categorize_lines(line):\n",
    "    header=re.search(r\"\\[(\\w+)\",line)\n",
    "    if header is None:\n",
    "        key=\"Moves\"\n",
    "        val=line\n",
    "    else:\n",
    "        key=header[1]\n",
    "        val=re.search(r\"\\\"(.+)\\\"\",line)[1]\n",
    "    return(key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all info into a list of dicts\n",
    "# Start with a clean list and a clean game dict\n",
    "my_list=[]\n",
    "game={}\n",
    "key=\"\"\n",
    "with open(arena_pgn) as pgn:\n",
    "    for line in pgn:\n",
    "        if key==\"Moves\":\n",
    "            my_list.append(game)\n",
    "            key=\"\"\n",
    "            game={}\n",
    "        entry=line.strip()\n",
    "        if entry!=\"\":\n",
    "            key,val=categorize_lines(entry)\n",
    "            # So far, this is what has been tested above\n",
    "            if key in cols:\n",
    "                game[key]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(my_list,columns=cols)\n",
    "df.drop(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows so we only get annotated games\n",
    "df[\"Eval\"]=df[\"Moves\"].apply(lambda x: \"eval\" in x)\n",
    "df=df[df[\"Eval\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the rating values are entered as numbers\n",
    "df[[\"WhiteElo\",\"BlackElo\"]]=df[[\"WhiteElo\",\"BlackElo\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output above, it seems that the conversion from pgn to dataframe has worked well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data wrangling\n",
    "So far, we have only extracted the data in \"raw\" form from the pgn file. A few more columns are needed before the analysis can be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating aCPL per player\n",
    "def get_aCPL(moves,start=0):\n",
    "    # Find all scores\n",
    "    scores=np.array(re.findall(r\"eval (-?[0-9]+\\.[0-9]+)\",str(moves)),dtype=float)\n",
    "    # Calculate score difference, move by move\n",
    "    CPL=abs(np.diff(scores))\n",
    "    # Calculate average score by color\n",
    "    aCPL_w=CPL[(start+1)::2].mean()*100\n",
    "    aCPL_b=CPL[start::2].mean()*100\n",
    "    num_moves=int(len(CPL)/2)\n",
    "    return(aCPL_w,aCPL_b,num_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blunders(moves,threshold):\n",
    "    # Find all scores\n",
    "    scores=np.array(re.findall(r\"eval (-?[0-9]+\\.[0-9]+)\",str(moves)),dtype=float)\n",
    "    # Calculate score difference, move by move\n",
    "    CPL=abs(np.diff(scores))\n",
    "    CPL_w=CPL[1::2]\n",
    "    CPL_b=CPL[::2]\n",
    "    blunders_w=len(CPL_w[CPL_w>threshold])\n",
    "    blunders_b=len(CPL_b[CPL_b>threshold])\n",
    "    return(blunders_w,blunders_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CPL per player and the number of moves per game\n",
    "df[\"white_cpl\"]=df[\"Moves\"].apply(lambda x: get_aCPL(x)[0])\n",
    "df[\"black_cpl\"]=df[\"Moves\"].apply(lambda x: get_aCPL(x)[1])\n",
    "df[\"num_moves\"]=df[\"Moves\"].apply(lambda x: get_aCPL(x)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create categories of players, by rating\n",
    "player_groups=[\"noob\",\"patzer\",\"grandpatzer\",\"master\",\"grandmaster\"]\n",
    "rtg_bins = [500,1400,1800,2200,2500,2700]\n",
    "\n",
    "# Then we add the category names to the dataframe\n",
    "df[\"category_w\"]=pd.cut(df['WhiteElo'].astype(\"int\",errors=\"ignore\"), rtg_bins, labels=player_groups, include_lowest=True)\n",
    "df[\"category_b\"]=pd.cut(df['BlackElo'].astype(\"int\",errors=\"ignore\"), rtg_bins, labels=player_groups, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rating difference between players\n",
    "df[\"Rating_diff\"]=df[\"BlackElo\"]-df[\"WhiteElo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of blunders per player\n",
    "# The threshold value here is 1.5 pawns (=1500 CP)\n",
    "df[\"blunders_w\"]=df[\"Moves\"].apply(lambda x: get_blunders(x,1.5)[0])\n",
    "df[\"blunders_b\"]=df[\"Moves\"].apply(lambda x: get_blunders(x,1.5)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the blunder rate\n",
    "df[\"blunder_rate_w\"]=df[\"blunders_w\"]/df[\"num_moves\"]\n",
    "df[\"blunder_rate_b\"]=df[\"blunders_b\"]/df[\"num_moves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows that all columns are complete, i.e. there are no non-null values (NaNs) in the dataset. Also, all the columns have appropriate datatypes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For starters, let's take a look at the descriptive statistics for the variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table above, we can make a number of observations:\n",
    "- The average rating is about 1770\n",
    "- The average CPL is just below 120, which is surprisingly high\n",
    "- The median CPL is considerably lower than the average, indicating an asymmetrical distribution\n",
    "- On average, a game lasts about 28 moves\n",
    "- On average, a player blunders 4 times during a game, or about 15% of the moves\n",
    "- The stats are almost identical for white and black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the distribution of players\n",
    "pd.DataFrame({\"White\": df[\"category_w\"].value_counts(),\"Black\":df[\"category_b\"].value_counts()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the players in the patzer and grandpatzer categories account for the vast  majority of players. The result of the analysis will therefore be most applicable for these groups. Also, there is only one player in the grandmaster group. Any conclusions from this data set regarding that group will therefore not be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"WhiteElo\",\"BlackElo\"]].plot.hist(bins=100, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see that the rating distributions are almost identical for white and black players. The spike at 1500 is probably because the starting rating for new accounts is 1500. The histograms are slightly skewed to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the players with a rating of exactly 1500.\n",
    "# Since the distributions are similar for both colors, we will use white as an example.\n",
    "df[df[\"WhiteElo\"]==1500].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows descriptive statistics for (white) players with a rating of *exactly* 1500. The distributions are approximately the same as for all players, indicating that the rating is not representative of the rating group overall. They will therefore be excluded from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove players with a rating of exactly 1500, so that they will not \"contaminate\" the results.\n",
    "df=df[df[\"WhiteElo\"]!=1500]\n",
    "df=df[df[\"BlackElo\"]!=1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After filtering out the 1500-players, the rating distribution looks like this (white only)\n",
    "df.groupby(\"category_w\")[\"WhiteElo\"].plot.hist(bins=100)\n",
    "plt.legend()\n",
    "plt.title(\"Histogram of player ratings\")\n",
    "plt.xlabel(\"Player rating (white)\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the correlations between the main variables\n",
    "# pd.plotting.scatter_matrix(df[[\"WhiteElo\",\"BlackElo\",\"white_cpl\",\"black_cpl\",\"blunder_rate_w\",\"blunder_rate_b\"]],figsize=(15,10))\n",
    "# plt.suptitle(\"Scatter matrix\",fontsize=15)\n",
    "# Has been removed to save space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also generate a correlation matrix\n",
    "print(\"Correlation matrix\")\n",
    "df[[\"WhiteElo\",\"BlackElo\",\"white_cpl\",\"black_cpl\",\"blunder_rate_w\",\"blunder_rate_b\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations from the matrix plot and correlation matrix:\n",
    "- There seems to be a correlation between the players' ratings. This suggests that players tend to be paired with players around their rating level.\n",
    "- CPL and rating seems to be correlated, but it is not very strong\n",
    "- Blunder rate and CPL have a quite strong correlation, but this is not so surprising, as the blunder rate is derived from the CPL scores\n",
    "- Interestingly, there seems to be a relatively strong correlation between CPL scores between players. This may be a result of the pairings, and that players of the same rating tend to have equal CPL scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the centipawn loss is the variable we're most interested in, let's take a closer look at the distribution of the variable.\n",
    "df[[\"white_cpl\",\"black_cpl\"]].plot.hist(bins=100, alpha=0.7)\n",
    "plt.title(\"Histogram of average centipawn loss\")\n",
    "plt.xlabel(\"Average centipawn loss (aCPL)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CPL scores resembles an exponential distribution, with a peak around 30 CPL and a long tail. The histograms are close to zero from around 600 CPL. This indicates that linear regression can be problematic, and that transformation may be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The quadratic root is often a good transformation of exponentially distributed data\n",
    "df[\"cpl_trans\"]=df[\"white_cpl\"].apply(lambda x: x**(1/4))\n",
    "plt.hist(df[\"cpl_trans\"],bins=100)\n",
    "plt.title(\"Transformed CPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the data with the quadratic root makes the distribution relatively symmetrical. This may facilitate the further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the transformation, the regression plot of rating versus CPL (transformed) looks like this:\n",
    "sns.regplot(y=df[\"WhiteElo\"],x=df[\"cpl_trans\"])\n",
    "plt.title(\"Regression plot\")\n",
    "plt.xlabel(\"CPL (transformed)\")\n",
    "plt.ylabel(\"Rating (white)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatter plot gives a much clearer indication of the correlation between CPL and rating. However, the regression line seems to be a bit flat. One would expect it to have a steeper slope and an intercept at about 2500. The orientation of the plot suggests that this could be a correct estimate, but that outliers influence the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(15,7))\n",
    "df.groupby(\"category_w\")[\"white_cpl\"].plot.hist(bins=100,alpha=0.6,ax=ax[0])\n",
    "df.groupby(\"category_w\")[\"cpl_trans\"].plot.hist(bins=100,alpha=0.6,ax=ax[1])\n",
    "ax[0].legend()\n",
    "plt.suptitle(\"Histogram of CPL by player group\",fontsize=15)\n",
    "ax[0].set_xlabel(\"CPL\")\n",
    "ax[1].set_xlabel(\"CPL (transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A slightly more simple plot is a bar plot of just the average values for each player group.\n",
    "fig,ax=plt.subplots(1,2,figsize=(15,7))\n",
    "plt.suptitle(\"CPL by player group\",fontsize=15)\n",
    "df.groupby(\"category_w\")[\"white_cpl\"].mean().plot.barh(ax=ax[0])\n",
    "df.groupby(\"category_w\")[\"cpl_trans\"].mean().plot.barh(ax=ax[1])\n",
    "ax[0].set_xlabel(\"CPL\")\n",
    "ax[1].set_xlabel(\"CPL (transformed)\")\n",
    "ax[0].set_ylabel(\"Player group\")\n",
    "ax[1].set_ylabel(\"Player group\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a similar plot for blunder rate\n",
    "df.groupby(\"category_w\")[\"blunder_rate_w\"].mean().plot.barh()\n",
    "plt.xlabel(\"Average blunder rate\\n(threshold=1.5)\")\n",
    "plt.title(\"Blunder rate per player group\",fontsize=15)\n",
    "plt.ylabel(\"Player group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots, we can conclude that our a priori assumptions about the relationships between player rating and the variables centipawn loss (CPL) and blunder rate, respectively, seems to hold fairly well at an overall level. Observe that the grandmaster category only consists of a single player, so the values are not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Lichess classical arena.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot()\n",
    "sns.kdeplot(df[\"WhiteElo\"],df[\"white_cpl\"],cmap=\"Reds\",shade=True,ax=ax,alpha=0.7)\n",
    "sns.kdeplot(df[\"BlackElo\"],df[\"black_cpl\"],cmap=\"Blues\",shade=True,ax=ax,alpha=0.3)\n",
    "ax.plot([750,2500],[140,10],\"g--\")\n",
    "ax.set_ylim(0,250)\n",
    "plt.title(\"Contour plot of player rating vs CPL\",fontsize=15)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"CPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot indicates that there is a clear relationship between rating and CPL. However, the amount of variation is huge. Just as an example, a CPL value of 50 gives a rating range of approximately 1400 to 2300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot()\n",
    "sns.kdeplot(df[\"WhiteElo\"],df[\"blunder_rate_w\"],cmap=\"Reds\",shade=True,ax=ax,alpha=0.7)\n",
    "sns.kdeplot(df[\"BlackElo\"],df[\"blunder_rate_b\"],cmap=\"Blues\",shade=True,ax=ax,alpha=0.3)\n",
    "ax.plot([750,2250],[0.4,0.01],\"g--\")\n",
    "ax.set_ylim(0,0.6)\n",
    "plt.title(\"Contour plot of player rating vs blunder rate\",fontsize=15)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Blunder rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Building a model\n",
    "Several attempts were made in this phase, and several models were discarded.\n",
    "- WhiteElo ~ white_cpl gives R2=0.082\n",
    "- WhiteElo ~ white_cpl + Rating_diff gives R2=.302. Quite good, but intercept=1854 - unreasonable\n",
    "- WhiteElo ~ white_cpl + Rating_diff + num_moves gives r2=0.371 and intercept=1675. num_moves has param 6.5\n",
    "- WhiteElo ~ white_cpl + Rating_diff + num_moves*blunders_w gives R2=0.410. Best R2 so far, but high condition no.\n",
    "- WhiteElo ~ white_cpl + Rating_diff + num_moves + blunder_rate_w gives R2=0.418, but a high condition no.\n",
    "- WhiteElo ~ white_cpl + Rating_diff + num_moves + blunders_w gives R2=0.401 and an acceptable condition no.\n",
    "- The transformed CPL values gave only a slightly better result, so for easier interpretation, the original CPL values are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=smf.ols(formula=\"WhiteElo ~ white_cpl + Rating_diff + num_moves + blunders_w\", data=df)\n",
    "result=model.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(result.resid,bins=100)\n",
    "plt.title(\"Histogram of residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals are quite large, indicating that the predictive value of the model is of little practical relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the full dataset\n",
    "So far, the analysis has been performed on just one of the players (white). We will therefore take another step and include both colors in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the rating difference is calculated from White's point of view, so the values have to be reversed\n",
    "white=pd.DataFrame({\"Rating\":df[\"WhiteElo\"],\"CPL\":df[\"white_cpl\"],\"RatingDiff\":df[\"Rating_diff\"],\"nmoves\":df[\"num_moves\"],\"nblunders\": df[\"blunders_w\"],\"category\":df[\"category_w\"]})\n",
    "black=pd.DataFrame({\"Rating\":df[\"BlackElo\"],\"CPL\":df[\"black_cpl\"],\"RatingDiff\":-df[\"Rating_diff\"],\"nmoves\":df[\"num_moves\"],\"nblunders\": df[\"blunders_b\"],\"category\":df[\"category_b\"]})\n",
    "df2=pd.concat([white,black])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Lichess stacked data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the same simple approach as above, plotting Rating vs CPL.\n",
    "ax=sns.kdeplot(df2[\"Rating\"],df2[\"CPL\"],cmap=\"Blues\",shade=True)\n",
    "ax.plot([750,2500],[140,10],\"g--\")\n",
    "ax.set_ylim(0,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope=(2500-750)/130\n",
    "round(slope,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this crude model holds quite well for the complete dataset. There is a clear orientation to the plot, but there is also a great deal of uncontrolled variation. According to this model, each CPL is worth about 13 rating points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the regression model with the full dataset\n",
    "full_model=smf.ols(\"Rating ~ CPL + RatingDiff + nmoves + nblunders\",data=df2)\n",
    "results2=full_model.fit()\n",
    "results2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 value drops slightly from the initial model (0.40 to 0.39), but the results are the same overall. All parameters are statistically significant, and we arrive at the following formula:\n",
    "<br><br>\n",
    "$Rating = 1655 - 0.20*CPL -0.45*RatingDiff + 8.55*nmoves -22*nblunders$\n",
    "<br><br>\n",
    "The parameter for CPL suggests that each CPL is worth only 0.2 rating points, and that the number of blunders is the main predictor with 22 rating points per blunder (threshold 1.5) along with the number of moves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the model prediction\n",
    "df2[\"Rating_pred\"]=results2.predict(df2[[\"CPL\",\"RatingDiff\",\"nmoves\",\"nblunders\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can evaluate the results by plotting the predicted values against the actual ratings\n",
    "sns.regplot(x=df2[\"Rating_pred\"],y=df2[\"Rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the correlation between predicted and actual values is ok. The regression line gives approximately the same results for both values. However, the main problem is that there is a lot of unexplained variation in the dataset. This reduces the predictive value of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results2.resid,bins=100)\n",
    "plt.title(\"Histogram of residuals\\nModel 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals resembles a standard distribution. The average seems to be around zero, and the standard deviation approximately 200. This means that we generally have a prediction error of $\\pm$ 400 rating points. This is quite a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(15,6))\n",
    "fig.suptitle(\"Residual plots vs observed and predicted rating\",fontsize=15)\n",
    "ax1=fig.add_subplot(121)\n",
    "ax2=fig.add_subplot(122)\n",
    "ax1.scatter(y=results2.resid,x=df2[\"Rating\"])\n",
    "ax1.set_xlabel(\"Rating\")\n",
    "ax2.scatter(y=results2.resid,x=df2[\"Rating_pred\"])\n",
    "ax2.set_xlabel(\"Predicted rating\")\n",
    "ax1.set_ylabel(\"Residual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no correlation between the residuals and the predicted values, but the residuals seem to increase with the actual rating values. This is consistent with our initial observations of the scatterplot of CPL vs Rating, where the variation was very high at low CPL levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the model to estimate performance\n",
    "As indicated above, the precision of this model is simply not good enough for accurately predicting playing strength from a single game. However, as with many things in life, consistency is a key factor. Therefore, it will be more relevant to test the model on several games from a single player.<br><br>\n",
    "Being a chess player myself, I don't mind being a guinea pig. I have therefore downloaded a list of annotated games from my own profile on lichess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My personal games\n",
    "my_pgn=\"lichess_Nietsoj_2020-05-19.pgn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the analysis will focus on my own games, we need to add player names for each game. Since I have played all of them, one color is enough. \n",
    "cols.append(\"White\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list=[]\n",
    "game={}\n",
    "key=\"\"\n",
    "with open(my_pgn) as pgn:\n",
    "    for line in pgn:\n",
    "        if key==\"Moves\":\n",
    "            my_list.append(game)\n",
    "            key=\"\"\n",
    "            game={}\n",
    "        entry=line.strip()\n",
    "        if entry!=\"\":\n",
    "            key,val=categorize_lines(entry)\n",
    "            if key in cols:\n",
    "                game[key]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(my_list,columns=cols)\n",
    "df3.drop(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been collected from the pgn file, but there are some adjustments that need to be made before moving forward. Lichess has different ratings for different time controls, so we need to identify the slower time controls, i.e. 15 minutes and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3[\"TimeControl\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the initial time for each game\n",
    "df3[\"TimeControl\"]=df3[\"TimeControl\"].apply(lambda x: int(x[:x.find(\"+\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested in timecontrols above 15 minutes, i.e. 900 seconds.\n",
    "df3=df3[df3[\"TimeControl\"]>=900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the rating values are entered as numbers\n",
    "df3[[\"WhiteElo\",\"BlackElo\"]]=df3[[\"WhiteElo\",\"BlackElo\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the CPL scores and number of moves\n",
    "df3[\"white_cpl\"]=df3[\"Moves\"].apply(lambda x: get_aCPL(x)[0])\n",
    "df3[\"black_cpl\"]=df3[\"Moves\"].apply(lambda x: get_aCPL(x)[1])\n",
    "df3[\"num_moves\"]=df3[\"Moves\"].apply(lambda x: get_aCPL(x)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rating difference between players\n",
    "df3[\"Rating_diff\"]=df3[\"BlackElo\"]-df3[\"WhiteElo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of blunders per player\n",
    "df3[\"blunders_w\"]=df3[\"Moves\"].apply(lambda x: get_blunders(x,1.5)[0])\n",
    "df3[\"blunders_b\"]=df3[\"Moves\"].apply(lambda x: get_blunders(x,1.5)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final dataset consists of 33 games. All the data has now been gathered, but we need one more step before we can perform the test. We need to separate the games I've played with white and black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_white=df3[df3[\"White\"]==\"Nietsoj\"]\n",
    "my_black=df3[df3[\"White\"]!=\"Nietsoj\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white=pd.DataFrame({\"Rating\":my_white[\"WhiteElo\"],\"CPL\":my_white[\"white_cpl\"],\"RatingDiff\":my_white[\"Rating_diff\"],\"nmoves\":my_white[\"num_moves\"],\"nblunders\": my_white[\"blunders_w\"]})\n",
    "black=pd.DataFrame({\"Rating\":my_black[\"BlackElo\"],\"CPL\":my_black[\"black_cpl\"],\"RatingDiff\":-my_black[\"Rating_diff\"],\"nmoves\":my_black[\"num_moves\"],\"nblunders\": my_black[\"blunders_b\"]})\n",
    "df4=pd.concat([white,black])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"Rating_pred\"]=1655-0.2*df4[\"CPL\"]-0.45*df4[\"RatingDiff\"]+8.55*df4[\"nmoves\"]-21.89*df4[\"nblunders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"pred_crude\"]=2635-df4[\"CPL\"]*slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[[\"Rating\",\"Rating_pred\",\"pred_crude\"]].plot(kind=\"box\",showfliers=False,showmeans=True)\n",
    "plt.title(\"Observed and predicted ratings\\nMy own games\",fontsize=13)\n",
    "plt.xticks([1,2,3],[\"Observed\",\"Regression\\nestimate\",\"Visual\\nestimate\"])\n",
    "plt.ylabel(\"Rating\")\n",
    "plt.savefig(\"Boxplot_my_rating.png\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38232bitce5d9d61daeb46beb2d649c4ee094365",
   "display_name": "Python 3.8.2 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}